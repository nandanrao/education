{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Run this notebook outside of main module tree\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "# ignore warnings!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from surveys.personality import *\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(model, X, y, name, cv=cv):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='f1')\n",
    "    return pd.DataFrame([{'model': name, 'mean': scores.mean(), 'std': scores.std()}]).set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "surveys = read_surveys('../data')\n",
    "X = prep_X(surveys)\n",
    "y = surveys.group == 'c'\n",
    "cv = ShuffleSplit(n_splits=100, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "ld_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "ld_factor = ld_model.fit_transform(X, y)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(C=.5)\n",
    "logistic_model.fit(X, y)\n",
    "logistic_factor = X.dot(logistic_model.coef_[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "svm_model = LinearSVC(C=1.)\n",
    "svm_model.fit(X, y)\n",
    "svc_factor = X.dot(svm_model.coef_[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "princ_comps = PCA(n_components=5).fit_transform(X)\n",
    "bf_survey = X.iloc[:, 0:65]\n",
    "bigfive_key = pd.read_csv(\"../data/educatalyst/Auxil/q1_key_bigfive.csv\", encoding='ISO-8859-1')\n",
    "bf_comps = get_big_five_comps(bigfive_key)\n",
    "bigfive = big_five_projection(bigfive_key, bf_survey)\n",
    "teique = X.filter(regex=\"^3\")\n",
    "grit = X.filter(regex=\"^4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Testing for Predictive Power of Survey Questions in Determining Group Membership\n",
    "\n",
    "Here we take the raw survey data and apply 3 linear classification algorithms that work well with the dimensionality of the data that we have (more features than observations). We choose linear because we are assuming that our data has a linear factor structure, and as such a linear algorithm will point to a single factor. LDA works directly on factors of the data explicitly, Linear Supper Vector Machines are a natural choice for a classification problem in high dimensions, and regularized Logistic Regression is, as well, as simple choice for a linear classifier. \n",
    "\n",
    "We measure out-of-sample \"F1\" score, an average of precision and recall, as a pure accuracy score would be misleading given our classes (groups) are not perfectly balanced. We do this on a randomized 1/4 test/training split of the data, which is repeated 100 times, from which we pull a mean and standard deviation of the scores to see if any classifier can predict significantly better than random given the survey data. They all fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               mean       std\nmodel                                        \nLDA                        0.585174  0.117171\nSVM                        0.638187  0.097601\nLogistic: All Survey Data  0.650731  0.090990"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [(ld_model, \"LDA\"), (svm_model, \"SVM\"), (logistic_model, \"Logistic: All Survey Data\")]\n",
    "\n",
    "pd.concat([get_scores(m, X, y, n) for m,n in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Testing the Predictive Power of Individual Surveys\n",
    "\n",
    "Next we look at individual surveys, for the Big Five we take the 5 factors themselves, for the other surveys we just use the individual questions as there are very few. We also take a look at a basic PCA decomposition of the entire set of 104 survey questions together. All of these features are attempted with the same regularlized Logistic Regression model, and nothing is proven to have any predictive power over group membership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  mean       std\nmodel                                           \nLogistic: Grit                0.561053  0.097679\nLogistic: Teique              0.596842  0.101025\nLogistic: Big Five            0.538947  0.111430\nLogistic: PCA on all Surveys  0.497895  0.109752"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=.5)\n",
    "\n",
    "li = [(grit, \"Logistic: Grit\"),\n",
    "      (teique, \"Logistic: Teique\"),\n",
    "      (bigfive, \"Logistic: Big Five\"),\n",
    "      (princ_comps, \"Logistic: PCA on all Surveys\")]\n",
    "\n",
    "pd.concat([get_scores(model, x, y, n) for x,n in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy / Extraversion', 'Agreeableness', 'Conscientiousness',\n       'Emotional Instability', 'Intellect / Openness'],\n      dtype='object')"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigfive.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# THE REST IS NOT REALLY AS INTERESTING!\n",
    "\n",
    "But here we see if how the factors we find with direct prediction compare to the big five traits. We see that, if anything, some factor that is most closely correlated with Conscientiousness and Emotional Instability has some power on predicting group membership in our cohort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              0         0         0         0\nEnergy / Extraversion  0.047290  0.045018  0.067458  0.041342\nAgreeableness          0.011719  0.015875  0.016532  0.030283\nConscientiousness     -0.111763 -0.153912 -0.195607 -0.148115\nEmotional Instability -0.143229 -0.190179 -0.090641 -0.060674\nIntellect / Openness  -0.010267 -0.029111 -0.185912 -0.115046"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = bigfive.as_matrix()\n",
    "def get_corr(bf, m):\n",
    "    try: \n",
    "        bf = bf.as_matrix()\n",
    "    except AttributeError:\n",
    "        bf = bf\n",
    "    return pd.DataFrame([np.corrcoef(i, m)[0,1] for i in bf.T])\n",
    "     \n",
    "df = pd.concat([get_corr(bigfive, ld_factor), get_corr(bigfive, logistic_factor), get_corr(princ_comps, logistic_factor), get_corr(princ_comps, ld_factor)], axis=1)\n",
    "df.index = bigfive.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53571429,  0.46428571,  0.38461538])"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = PLSSVD(n_components=5)\n",
    "model.fit(X1, X2)\n",
    "\n",
    "def make_transformed_training(A,B):\n",
    "    a = np.repeat(1, A.shape[0])\n",
    "    b = np.repeat(0, B.shape[0])\n",
    "    groups = np.concatenate([a,b])\n",
    "    return np.concatenate([A, B]), groups\n",
    "    \n",
    "# np.array.concat(model.x_scores_, model.y_scores_)\n",
    "X, y = make_transformed_training(model.x_scores_, model.y_scores_)\n",
    "model = LogisticRegression()\n",
    "cross_val_score(model, X, y)"
   ]
  }
 ],
 "metadata": {
  "name": "group-differences.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
