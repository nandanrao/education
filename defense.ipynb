{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Personality\n",
    "\n",
    "## Intro\n",
    "Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import SparsePCA, PCA\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import personality\n",
    "import factors\n",
    "reload(personality)\n",
    "reload(factors)\n",
    "from personality import *\n",
    "from factors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from factor_rotation._wrappers import rotate_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = prep_X(read_surveys())\n",
    "bf_survey = X.iloc[:, 0:65]\n",
    "bf_survey_scaled = pd.DataFrame(scale(bf_survey))\n",
    "others = X.iloc[:, 65:]\n",
    "others_scaled = pd.DataFrame(scale(others))\n",
    "ids = read_surveys().user_id\n",
    "\n",
    "# Get the big five components, sparse positie loadings for the questions that\n",
    "# refer to personality traits. \n",
    "bigfive_key = pd.read_csv(\"educatalyst/Auxil/q1_key_bigfive.csv\")\n",
    "bf_comps = get_big_five_comps(bigfive_key)\n",
    "\n",
    "# Projec the survey data onto those big five personality components\n",
    "bigfive = big_five_projection(bigfive_key, bf_survey)\n",
    "bigfive_scaled = big_five_projection(bigfive_key, bf_survey_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bigfive.to_csv(\"clean_data/bigfive.csv\", index=False)\n",
    "bf_survey.to_csv(\"clean_data/bigfive_survey.csv\", index=False)\n",
    "others.to_csv(\"clean_data/others.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_projected_variance(df, comps, p = 5):\n",
    "    projected = df.dot(normalize(comps).T)\n",
    "    v =  np.var(projected)/np.var(df).sum() * 100 \n",
    "    print 'Summed variance of first %s components: %s' % (p,v[0:p].sum())\n",
    "    return v\n",
    "\n",
    "def plot_corr(A, B):\n",
    "    corr = np.corrcoef(F, bigfive, rowvar = False)\n",
    "    p = sns.heatmap(pd.DataFrame(corr))\n",
    "    plt.show()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed variance of first 5 components: 46.0333921325\n",
      "Summed variance of first 5 components: 46.0333921325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 18.40555681,  11.99694605,   6.14657412,   5.06260598,\n",
       "          4.42170918],\n",
       "       [ 13.9356478 ,   7.4355079 ,   7.79088151,   9.59363506,\n",
       "          7.27771987]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance described by pure PCA of others survey space\n",
    "others_pca = PCA(5).fit(others_scaled)\n",
    "# get_projected_variance(others, others_pca.components_)\n",
    "A = others_pca.components_\n",
    "V, T = rotate_factors(A.T, 'varimax')\n",
    "np.stack([get_projected_variance(others_scaled, A), get_projected_variance(others_scaled, V.T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# projection of X into subspace of V\n",
    "P = V.dot(V.T)\n",
    "X_proj = others_scaled.dot(P)\n",
    "np.allclose(X_proj, X_proj.dot(P))\n",
    "\n",
    "bf_proj = bigfive.dot(bf_comps.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "others_pca = PCA(5).fit(others_scaled)\n",
    "\n",
    "A = others_pca.components_\n",
    "V, T = rotate_factors(A.T, 'varimax')\n",
    "# V, T = rotate_factors(A.T, 'oblimin', .635, 'oblique')\n",
    "\n",
    "\n",
    "# Comparing the LL' - \\Psi to \\Sigma! <-- error rate to optimize?? This is for orthogonality??\n",
    "dif = np.cov(others_scaled.T) - V.dot(V.T)\n",
    "off_diag = dif - np.diag(np.diag(dif))\n",
    "print np.linalg.norm(np.cov(others_scaled.T)), np.linalg.norm(off_diag)\n",
    "\n",
    "# np.diag(np.mean(F.dot(F.T)))\n",
    "# others_scaled.dot(A.T)\n",
    "# normalize(V)\n",
    "# fit the form of Ax = B, we need to transpose everything from our basic X = FL' form\n",
    "F = np.linalg.lstsq(V, others_scaled.T)[0].T\n",
    "\n",
    "# Ratio norm of difference between projected others_scaled\n",
    "print 1 - np.linalg.norm(others_scaled - F.dot(V.T))/np.linalg.norm(others_scaled)\n",
    "# Ratio of variane between projected and others_scaled\n",
    "print 1 - np.var(others_scaled - F.dot(V.T)).sum() / np.var(others_scaled).sum()\n",
    "\n",
    "# This is only the same if we go with orthogonal factors!\n",
    "# F = others_scaled.dot(V)\n",
    "\n",
    "# Look at loadings matrix just like in Norman paper :D\n",
    "print np.round(F * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e21b4af50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In both cases, that of the big five survey and that of our others survey,\n",
    "# there seems to be a single strong \"general\" component that is highly correlated\n",
    "# with all the factors from the bigfive. This could definitely indicate a\n",
    "# misspecification of the surveys themselves. \n",
    "\n",
    "bf_survey_pca = PCA(5).fit(bf_survey_scaled)\n",
    "loadings = bf_survey_pca.components_.T\n",
    "V, T = rotate_factors(loadings, 'varimax')\n",
    "VO, T = rotate_factors(loadings, 'oblimin', .635, 'oblique')\n",
    "\n",
    "corr = np.corrcoef(bf_survey_scaled.dot(loadings), bigfive, rowvar=False)\n",
    "sns.heatmap(pd.DataFrame(corr).iloc[0:5,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e236a9fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = np.corrcoef(bf_survey_scaled.dot(V), bigfive, rowvar=False)\n",
    "sns.heatmap(pd.DataFrame(corr).iloc[0:10,0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32410222  0.17678225  0.34087297  0.03021434  0.83446009]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e23e8f410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F = bf_survey_scaled.dot(VO)\n",
    "plot_corr(F, bigfive)\n",
    "print max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96410928  0.92882687  0.88717368  0.97659425  0.92241772]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e23e88890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = target_rotation(bf_survey_scaled.dot(V), bigfive)\n",
    "F = bf_survey_scaled.dot(V.dot(T))\n",
    "\n",
    "p = plot_corr(F, bigfive)\n",
    "print max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95981849  0.93806137  0.89642417  0.97785646  0.91152155]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e238e0d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ff(A, T, L=None):\n",
    "    L = A.dot(T)\n",
    "    # return np.linalg.norm(normalize(L) - np.array(bigfive_scaled))\n",
    "    cor_sum = (max_corr(L, np.array(bigfive))).sum()\n",
    "    return 1/cor_sum\n",
    "\n",
    "T = target_rotation(bf_survey_scaled.dot(V), bigfive)\n",
    "T = GPA(bf_survey_scaled.dot(V), ff, T = T, max_tries=2001)[2]\n",
    "F = bf_survey_scaled.dot(V.dot(T))\n",
    "plot_corr(F, bigfive)\n",
    "print max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = VO.dot(T)\n",
    "T2 = target_rotation(bf_survey_scaled.dot(V), bigfive)\n",
    "A2 = V.dot(T2)\n",
    "print get_projected_variance(bf_survey, A.T)\n",
    "print get_projected_variance(bf_survey, A2.T)\n",
    "print get_projected_variance(bf_survey, bf_survey_pca.components_)\n",
    "print get_projected_variance(bf_survey, bf_comps.T)\n",
    "\n",
    "# print np.linalg.norm(normalize(bigfive) - normalize(bf_survey.dot(A)))\n",
    "# print np.linalg.norm(normalize(bigfive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef(F, bigfive, rowvar=False)\n",
    "p = sns.heatmap(pd.DataFrame(corr).iloc[0:5,0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55258204  0.54914326  0.6538904   0.47154529  0.6688041 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e21858ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from factor_rotation._analytic_rotation import target_rotation\n",
    "from factor_rotation._gpa_rotation import orthomax_objective\n",
    "\n",
    "others_pca = PCA(5).fit(others_scaled)\n",
    "A = others_pca.components_.T\n",
    "\n",
    "\n",
    "# fn = lambda A: max_corr(A, bigfive).sum()\n",
    "varimax = lambda A: orthomax_objective(L, gamma=1, return_gradient=False)\n",
    "F = others_scaled.dot(A)\n",
    "_,T = get_best_rotation(F, bigfive, target_rotation, varimax)\n",
    "F = others_scaled.dot(A.dot(T))\n",
    "\n",
    "plot_corr(F, bigfive)\n",
    "print max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from factor_rotation._gpa_rotation import GPA, rotateA as rotate\n",
    "\n",
    "others_pca = PCA(5).fit(others_scaled)\n",
    "A = others_pca.components_.T\n",
    "\n",
    "def ff(A, T, L=None):\n",
    "    V = rotate(A, T, 'oblique')\n",
    "    F = np.linalg.lstsq(V, others_scaled.T)[0].T\n",
    "    # return np.linalg.norm(normalize(L) - np.array(bigfive_scaled))\n",
    "    cor_sum = (max_corr(F, bigfive)).sum()\n",
    "    return 1/cor_sum\n",
    "\n",
    "# create initial optimization target with orthogonal targeting\n",
    "F = others_scaled.dot(A)\n",
    "T = target_rotation(F, bigfive)\n",
    "\n",
    "varimax = lambda A: orthomax_objective(L, gamma=1, return_gradient=False)\n",
    "\n",
    "def get_rotation(A, H):\n",
    "    F = others_scaled.dot(A)\n",
    "    T = target_rotation(F, H)\n",
    "    _,_,T,_ = GPA(A, ff, T=T, rotation_method='oblique')\n",
    "    return T \n",
    "\n",
    "_,T = get_best_rotation(A, bigfive, get_rotation, varimax)\n",
    "# L = rotate(A, T, 'oblique')\n",
    "# F = np.linalg.lstsq(L, others_scaled.T)[0].T\n",
    "# corr = np.corrcoef(F, bigfive, rowvar = False)\n",
    "# sns.heatmap(corr)\n",
    "# plt.show()\n",
    "# max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74498231,  0.74498232,  0.75974714,  0.53259004,  0.75594049])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e21aab8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = rotate(A, T, 'oblique')\n",
    "F = np.linalg.lstsq(L, others_scaled.T)[0].T\n",
    "corr = np.corrcoef(F, bigfive, rowvar = False)\n",
    "sns.heatmap(corr)\n",
    "plt.show()\n",
    "max_corr(F, bigfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, pdist, squareform\n",
    "from factor_rotation._gpa_rotation import GPA\n",
    "\n",
    "\n",
    "T = GPA(F, )\n",
    "rotated_factors = F.dot(T)\n",
    "# f,b = [np.array(df) for df in [rotated_factors, bigfive]]\n",
    "# cos = squareform(pdist(np.concatenate([f.T,b.T]), 'cosine'))\n",
    "# sns.heatmap(cos)\n",
    "# plt.show()\n",
    "# sum([cos[1,6], cos[2,7], cos[4,9], cos[3,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import DictionaryLearning\n",
    "\n",
    "others_dict = DictionaryLearning(5).fit(others_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/cross_decomposition/pls_.py:83: UserWarning: Maximum number of iterations reached\n",
      "  warnings.warn('Maximum number of iterations reached')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "cca = CCA(n_components = 38)\n",
    "res = cca.fit_transform(bf_survey, others)\n",
    "bf_ccas = res[0]\n",
    "others_ccas = res[1]\n",
    "# get_projected_variance(bf_survey.T, bf_ccas.T), get_projected_variance(others.T, others_ccas.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 5), (94, 38))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = others.dot(others_pca.components_.T)\n",
    "# F.dot(others.T)\n",
    "F.shape, others.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.629493\n",
       "1    10.414766\n",
       "2     7.607404\n",
       "3     5.766579\n",
       "4     6.323208\n",
       "5     5.765240\n",
       "6     4.522215\n",
       "7     7.120568\n",
       "dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed variance of first 5 components: 40.7414493917\n"
     ]
    }
   ],
   "source": [
    "# Variance described by Sparse PCA in others survey space\n",
    "others_sparse_pca = SparsePCA(8, .8).fit(others)\n",
    "get_projected_variance(others, others_sparse_pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the space of the Big Five survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Variance described by Big Five Regression from others survey space\n",
    "get_projected_variance(others, enet.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Variance explained by official Big Five Mapping\n",
    "get_projected_variance(bf_survey, bf_comps.T)\n",
    "\n",
    "# varimax gives reasonable results here, leaves everything unchanged... \n",
    "# V,T = rotate_factors(bf_comps.T, 'varimax')\n",
    "# bf_comps.T - V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Variance explained by pure PCA\n",
    "bf_survey_pca = PCA(5).fit(bf_survey)\n",
    "# get_projected_variance(bf_survey, bf_survey_pca.components_)\n",
    "A = bf_survey_pca.components_\n",
    "V, _ = rotate_factors(A, 'varimax')\n",
    "# get_projected_variance(bf_survey, V)\n",
    "# np.round(V*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6.954491\n",
       "1    12.506588\n",
       "2     5.411025\n",
       "3     9.582842\n",
       "4     7.341020\n",
       "5     6.396424\n",
       "6     4.112881\n",
       "7     7.628662\n",
       "dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed variance of first 5 components: 41.7959663825\n"
     ]
    }
   ],
   "source": [
    "# Variance explained by Sparse PCA\n",
    "bf_survey_sparse_pca = SparsePCA(8, .8).fit(bf_survey)\n",
    "get_projected_variance(bf_survey, bf_survey_sparse_pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  0.],\n       [ 0.,  1.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from factor_rotation._gpa_rotation import GPA\n",
    "a = np.array([[0.01,1.0], [1,0.01]])\n",
    "b = np.array([[-1.0,0.01], [0.01, 1.0]])\n",
    "\n",
    "def ff(A, T, L=None):\n",
    "    # print \"translate\"\n",
    "    # print T\n",
    "    L = A.dot(T)\n",
    "    # print L\n",
    "    p = (L).dot(b.T).sum()\n",
    "    # print p\n",
    "    return 1/p\n",
    "\n",
    "a = GPA(a, ff, max_tries = 2001)\n",
    "np.round(a[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "defense.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
